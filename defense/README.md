# Defense for Team Stanford & Suns

### Summary

Our defense is an ensemble of 8 models with weights determined by another 5 models using the following ideas:

1. Preprocessing the input by converting from `.png` to `.jpg` and back
2. Adding a random convolutional filter to a pretrained model (Xception) and finetuning
3. Scoring the performance of a set of models `M1` against attackers by scoring them based on agreement with a set of models `M2` on a subset of the inputs where the models in `M2` have high agreement.

We found that (1) and (2) lowered classification accuracy against weak attacks, but increased resistance dramatically against strong attacks.  In particular, we found that the random filters in (2) decreased transfer even from attacks trained against similar network architectures to Xception without use of adversarial training. 

In order to make use of this increased resistance without reducing classification accuracy too much against weak attacks, we used idea (3) to favor the best performing models against a specific attack.  Notably, we found that even when the best models in `M1` had higher classifcation accuracy than every model in `M2`, their scores on inputs where models in `M2` had high agreement were predictive of overall accuracy.  This allowed us to put models along the full spectrum of the `(classification accuracy, adversarial resistance)` tradeoff curve in `M1` while scoring them on models with especially high resistance but slightly lower accuracy in `M2`.

### Model Sets

The models we use in the ensemble are the 4 adversarially trained models available in `tf.slim` as well as the same four models applied to the image after conversion from `.png` to `.jpg` and back at quality `15`.

* `ens_adv_inception_resnet_v2`
* `adv_inception_v3`
* `ens3_adv_inception_v3`
* `ens4_adv_inception_v3`
* `ens_adv_inception_resnet_v2_jpg15`
* `adv_inception_v3_jpg15`
* `ens3_adv_inception_v3_jpg15`
* `ens4_adv_inception_v3_jpg15`

The models we use to score the ensemble were generated by taking the pretrained [Xception](https://github.com/fchollet/keras/blob/master/keras/applications/xception.py) model from Keras, prepending a random convolutional filter, and training for 100K images on ImageNet.  We chose the 5 models with best training set performance out of 24 total models and preprocess the input by conversion from `.png` to `.jpg` and back at quality `15`.  These models have lower classification accuracy since the random filter destroys information, but we found them to be more resistant to adversarial attacks.

* `rand_xception1`
* `rand_xception2`
* `rand_xception3`
* `rand_xception4`
* `rand_xception5`

We define the following 4 sets of models:

* `Simple`: `[ens_adv_inception_resnet_v2, adv_inception_v3, ens3_adv_inception_v3, ens4_adv_inception_v3]`
* `Hard`: `Simple` + `[ens_adv_inception_resnet_v2_jpg15, adv_inception_v3_jpg15, ens3_adv_inception_v3_jpg15, ens4_adv_inception_v3_jpg15]`
* `Simple Vote`: `[ens_adv_inception_resnet_v2_jpg15, adv_inception_v3_jpg15, ens3_adv_inception_v3_jpg15, ens4_adv_inception_v3_jpg15]`
* `Hard Vote`: `[rand_xception1, rand_xception2, rand_xception3, rand_xception4, rand_xception5]`

Models in `Simple` have higher classification accuracy but lower adversarial resistance than models in `Hard`, `Simple Vote`, or `Hard Vote`. 

### Ensembling Method

Our ensembling method attempts to select the group of models with greatest classification accuracy which is still resistant to the attack under consideration.  We apply the concept of an **(X,Y)-agreement set**, which is the set of test images on which at least `X` of a set of `Y` models return the same label.  In experiments, we found that the models in `Simple Vote` and `Hard Vote` perform well on their respective agreement sets.  In addition, when the agreement sets were sufficiently large, we found that the agreement of another model `M` with `Simple Vote` and `Hard Vote` on the agreement set predicted the overall performance of `M`, even when `M` had better peformance than any single model in `Simple Vote` or `Hard Vote`.  Our method balances this signal with our prior knowledge of the difference in classification accuracy of the pretrained models we are using.

Our final method is as follows. On each batch of 100, we first evaluate all models on all images.  We then proceed in several stages, using two manually tuned thresholds `back_off_thresh = 0.7` and `med_thresh = 0.75`:

1. We score each model in `Simple` based on its agreement with the majority vote of the models in `Simple`.  If the median of scores is at least `back_off_thresh`, we commit to using the models in `Simple` (Case A).  Otherwise, we back off to the models in `Hard` (Case B).
2. In Case A, if the score of `ens_adv_inception_resnet_v2` is at least `med_thresh`, we apply weighted voting of the models in `Simple` with manually chosen weights `[2.9, 1.0, 1.0, 1.0]`; this reflects our prior that `ens_adv_inception_resnet_v2` has the best classfication accuracy.  Otherwise, we back off to Case A2.
3. In Case A2, we determine a (X, 4)-agreement set `S` for `Simple Vote` with `X` chosen to be maximal so that `S` has size at least `60`.  If `X` is at least `3`, we apply weighted voting of the models in `Simple` with weights given by their score on `S` raised to the `10`th power.  Otherwise, we apply weighted voting of the models in `Simple` with weights given by their score on the majority vote on all images raised to the `10`th power.
4. In Case B, we determine a (X, 5)-agreement set `H` for `Hard Vote` with `X` chosen to be maximal so that `S` has size at least `60`.  If `X` is at least `3`, we apply weighted voting of the models in `Hard` with weights given by their score on `H` raised to the `10`th power.  Otherwise, we apply weighted voting of the models in `Hard` with manually chosen weights `[0.0, 0.0, 0.0 0.0, 2.9, 1.0, 1.0, 1.0]`.

### Code and Thanks

Our code implementing this defense is available [here](https://github.com/ftramer/stanford-suns-nips17).  In addition to the publically available checkpoint files which may be downloaded by running `model_ckpts/download_all.sh`, our defense requires custom trained weight files `nothing_xception_*.pb` which are available upon request. These checkpoint and weight files should be placed in directory `model_ckpts`.

Many thanks to the organizers for running this enjoyable competition!
